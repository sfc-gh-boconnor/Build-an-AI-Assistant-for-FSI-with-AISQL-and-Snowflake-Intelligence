-- =====================================================
-- FSI Cortex Assistant - Data Foundation (STREAMLINED)
-- =====================================================
-- This script loads ONLY raw/base data tables
-- AI-processed tables are generated by notebooks
-- =====================================================

ALTER SESSION SET QUERY_TAG = '''{"origin":"sf_sit-is", "name":"Build an AI Assistant for FSI using AISQL and Snowflake Intelligence", "version":{"major":1, "minor":0},"attributes":{"is_quickstart":1, "source":"sql"}}''';

-- Use ACCOUNTADMIN for all object creation
USE ROLE ACCOUNTADMIN;
USE WAREHOUSE DEFAULT_WH;

-- Set database context (required for stage creation)
USE DATABASE ACCELERATE_AI_IN_FSI;
USE SCHEMA DEFAULT_SCHEMA;

-- =====================================================
-- 1. EMAIL_PREVIEWS Table (Raw Email Data)
-- =====================================================
-- 324 realistic financial analyst emails
-- Used by: Notebook 1 (EMAIL_PREVIEWS_EXTRACTED), SEND_EMAIL_NOTIFICATION procedure
-- =====================================================

CREATE TABLE IF NOT EXISTS ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS (
    EMAIL_ID VARCHAR(100) PRIMARY KEY,
    RECIPIENT_EMAIL VARCHAR(500),
    SUBJECT VARCHAR(1000),
    HTML_CONTENT VARCHAR(16777216),
    CREATED_AT TIMESTAMP_NTZ
);

-- Create unified stage for data files from Git repository
CREATE OR REPLACE STAGE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.data_files_stage
  FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = '|'
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
    TRIM_SPACE = FALSE
  );

-- Copy and load email previews
COPY FILES
INTO @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.data_files_stage
FROM @SNOWFLAKE_QUICKSTART_REPOS.GIT_REPOS.ACCELERATE_AI_IN_FSI_REPO/branches/main/assets/data/
FILES = ('email_previews_data.csv');

TRUNCATE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS;

COPY INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS (
    EMAIL_ID,
    RECIPIENT_EMAIL,
    SUBJECT,
    HTML_CONTENT,
    CREATED_AT
)
FROM @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.data_files_stage/email_previews_data.csv
FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = '|'
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
    TRIM_SPACE = FALSE
)
ON_ERROR = 'CONTINUE'
PURGE = TRUE;

GRANT SELECT, INSERT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS TO ROLE ACCOUNTADMIN;
GRANT SELECT, INSERT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS TO ROLE PUBLIC;

-- Grant to SnowMail app if it exists (prevents losing access if script 02 is re-run after script 07)
-- This will fail silently if the app doesn't exist yet - that's OK, script 07 will grant when app is created
BEGIN
    GRANT SELECT, INSERT, DELETE ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS TO APPLICATION SNOWMAIL;
EXCEPTION
    WHEN OTHER THEN
        -- App doesn't exist yet, ignore
        NULL;
END;

-- =====================================================
-- 2. unique_transcripts Table (Raw Transcript Data)
-- =====================================================
-- Raw earnings call transcript JSON
-- Used by: Notebook 2 for AI_TRANSCRIBE processing
-- =====================================================

CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts (
	primary_ticker VARCHAR(16777216),
	event_timestamp TIMESTAMP_NTZ(9),
	event_type VARCHAR(16777216),
	created_at TIMESTAMP_NTZ(9),
	transcript VARCHAR(16777216)
);

CREATE TEMPORARY STAGE IF NOT EXISTS ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts_stage
  FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = ','
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
    TRIM_SPACE = FALSE
  );

-- Copy file from Git repository to stage first
COPY FILES
INTO @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts_stage
FROM @SNOWFLAKE_QUICKSTART_REPOS.GIT_REPOS.ACCELERATE_AI_IN_FSI_REPO/branches/main/assets/data/
FILES = ('unique_transcripts.csv');

TRUNCATE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts;

COPY INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts
FROM @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts_stage/unique_transcripts.csv
FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = ','
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
    TRIM_SPACE = FALSE
)
ON_ERROR = 'CONTINUE'
PURGE = TRUE;

DROP STAGE IF EXISTS ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts_stage;

GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts TO ROLE ACCOUNTADMIN;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts TO ROLE PUBLIC;

-- =====================================================
-- 3. STOCK_PRICE_TIMESERIES & STOCK_PRICES (Raw Stock Data)
-- =====================================================
-- Historical stock price data
-- Used by: Notebook 3 (ML Model), Agent tools
-- =====================================================

CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICE_TIMESERIES(
	TICKER VARCHAR(16777216),
	ASSET_CLASS VARCHAR(16777216),
	PRIMARY_EXCHANGE_CODE VARCHAR(16777216),
	PRIMARY_EXCHANGE_NAME VARCHAR(16777216),
	DATE DATE,
	YEAR NUMBER(38,0),
	MONTHNO NUMBER(38,0),
	MONTHNAME VARCHAR(16777216),
	ALL_DAY_LOW FLOAT,
	ALL_DAY_HIGH FLOAT,
	PRE_MARKET_OPEN FLOAT,
	POST_MARKET_CLOSE FLOAT,
	NASDAQ_VOLUME NUMBER(38,0)
);

-- Create temporary stage for parquet file
CREATE TEMPORARY STAGE IF NOT EXISTS stock_price_stage;

-- Copy parquet file from Git repository to regular stage
COPY FILES
INTO @stock_price_stage
FROM @SNOWFLAKE_QUICKSTART_REPOS.GIT_REPOS.ACCELERATE_AI_IN_FSI_REPO/branches/main/assets/data/
FILES = ('stock_price_timeseries_snow.parquet');

-- Load from parquet with column name matching
COPY INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICE_TIMESERIES
FROM @stock_price_stage/stock_price_timeseries_snow.parquet
FILE_FORMAT = (TYPE = PARQUET)
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

DROP STAGE IF EXISTS stock_price_stage;

-- Create derived STOCK_PRICES table
CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICES AS
SELECT * FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICE_TIMESERIES;

GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICE_TIMESERIES TO ROLE ACCOUNTADMIN;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICE_TIMESERIES TO ROLE PUBLIC;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICES TO ROLE ACCOUNTADMIN;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICES TO ROLE PUBLIC;

-- =====================================================
-- 4. AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS (Raw Sentiment Data)
-- =====================================================
-- Pre-aggregated analyst sentiment scores
-- Used by: Agent tools, Cortex Analyst semantic views
-- =====================================================

CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS (
	primary_ticker VARCHAR(16777216),
	event_timestamp TIMESTAMP_NTZ(9),
	event_type VARCHAR(16777216),
	created_at TIMESTAMP_NTZ(9),
	sentiment_score NUMBER(38,0),
	unique_analyst_count NUMBER(38,0),
	sentiment_reason VARCHAR(16777216)
);

-- Copy file from Git repository to regular stage first
COPY FILES
INTO @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.data_files_stage
FROM @SNOWFLAKE_QUICKSTART_REPOS.GIT_REPOS.ACCELERATE_AI_IN_FSI_REPO/branches/main/assets/data/
FILES = ('ai_transcripts_analysts_sentiments.csv');

TRUNCATE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS;

COPY INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS
FROM @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.data_files_stage/ai_transcripts_analysts_sentiments.csv
FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = ','
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
    TRIM_SPACE = FALSE
)
ON_ERROR = 'CONTINUE'
PURGE = TRUE;

GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS TO ROLE ACCOUNTADMIN;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS TO ROLE PUBLIC;

-- =====================================================
-- 5. SOCIAL_MEDIA_NRNT (Raw Social Media Data)
-- =====================================================
-- Social media posts about NRNT collapse
-- Contains 800+ posts with sentiment and image references
-- =====================================================

CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SOCIAL_MEDIA_NRNT (
	POST_ID VARCHAR(16777216),
	USER_HANDLE VARCHAR(16777216),
	TIMESTAMP_POST TIMESTAMP_NTZ(9),
	TICKER VARCHAR(16777216),
	POST_TEXT VARCHAR(16777216),
	SENTIMENT NUMBER(18,0),
	LIKES NUMBER(18,0),
	RETWEETS NUMBER(18,0),
	IMAGE_FILENAME VARCHAR(16777216)
);

CREATE TEMPORARY STAGE IF NOT EXISTS ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.social_media_stage
  FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = ','
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
  );

-- Copy file from Git repository to stage first
COPY FILES
INTO @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.social_media_stage
FROM @SNOWFLAKE_QUICKSTART_REPOS.GIT_REPOS.ACCELERATE_AI_IN_FSI_REPO/branches/main/assets/data/
FILES = ('social_media_nrnt_collapse.csv');

COPY INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SOCIAL_MEDIA_NRNT
FROM @ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.social_media_stage/social_media_nrnt_collapse.csv
FILE_FORMAT = (
    TYPE = CSV
    FIELD_DELIMITER = ','
    SKIP_HEADER = 1
    FIELD_OPTIONALLY_ENCLOSED_BY = '"'
    ESCAPE = '\\'
    ESCAPE_UNENCLOSED_FIELD = '\\'
    ENCODING = 'UTF8'
    NULL_IF = ('NULL', 'null', '')
)
ON_ERROR = 'CONTINUE';

DROP STAGE IF EXISTS ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.social_media_stage;

GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SOCIAL_MEDIA_NRNT TO ROLE ACCOUNTADMIN;
GRANT SELECT ON TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SOCIAL_MEDIA_NRNT TO ROLE PUBLIC;

-- =====================================================
-- SEND_EMAIL_NOTIFICATION Procedure
-- =====================================================
-- Python procedure for sending emails with markdown-to-HTML conversion
-- Stores emails in EMAIL_PREVIEWS table for SnowMail viewer
-- =====================================================

CREATE OR REPLACE PROCEDURE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SEND_EMAIL_NOTIFICATION(
    EMAIL_SUBJECT VARCHAR,
    EMAIL_CONTENT VARCHAR,
    RECIPIENT_EMAIL VARCHAR DEFAULT 'analyst@oneticker.demo',
    MIME_TYPE VARCHAR DEFAULT 'text/html'
)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python', 'markdown')
HANDLER = 'send_email'
COMMENT='Sends email notifications using SYSTEM$SEND_EMAIL with snowflake_intelligence_email_int integration. Automatically converts markdown to HTML with Snowflake brand styling.'
EXECUTE AS OWNER
AS
$$
import snowflake.snowpark as snowpark
import markdown
import re

def send_email(session: snowpark.Session, email_subject: str, email_content: str, 
               recipient_email: str = 'demo@snowflake.com', 
               mime_type: str = 'text/html') -> str:
    
    # Validate required parameters
    if not email_subject or not email_subject.strip():
        return 'ERROR: Email subject cannot be empty'
    
    if not email_content or not email_content.strip():
        return 'ERROR: Email content cannot be empty'
    
    # Use default recipient if none provided
    if not recipient_email or not recipient_email.strip():
        recipient_email = 'analyst@oneticker.demo'
    
    # Generate unique filename
    import time
    import hashlib
    timestamp = str(int(time.time() * 1000))
    email_id = hashlib.md5(f"{recipient_email}{timestamp}".encode()).hexdigest()[:12]
    filename = f"email_{email_id}.html"
    
    # Convert markdown to HTML
    if mime_type == 'text/html':
        email_content = email_content.replace('\n==========\n', '\n')
        email_content = email_content.replace('\n====\n', '\n')
        
        html_body = markdown.markdown(
            email_content,
            extensions=['nl2br', 'tables', 'fenced_code']
        )
        
        # Snowflake brand styling
        html_body = html_body.replace('<li>', '<li style="color: #000000;">')
        html_body = html_body.replace('<strong>', '<strong style="color: #29B5E8; font-weight: 700;">')
        html_body = html_body.replace('<h2>', '<h2 style="color: #29B5E8; font-weight: 700; margin: 18px 0 8px 0; font-size: 18px; border-bottom: 2px solid #29B5E8; padding-bottom: 5px;">')
        
        # Create email viewer HTML
        from datetime import datetime
        current_time = datetime.now().strftime("%B %d, %Y at %I:%M %p")
        
        html_content = f"""<!DOCTYPE html><html><head><meta charset="UTF-8">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700;900">
        <title>{email_subject}</title>
        <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: Lato, Arial, sans-serif; background-color: #f5f7fa; padding: 20px; }}
        .email-viewer {{ max-width: 900px; margin: 0 auto; background-color: white; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); overflow: hidden; }}
        .email-header {{ background: linear-gradient(135deg, #29B5E8 0%, #146892 100%); color: white; padding: 25px 30px; }}
        .email-subject {{ font-size: 24px; font-weight: 700; margin-bottom: 15px; }}
        .email-meta {{ display: flex; flex-wrap: wrap; gap: 20px; font-size: 14px; opacity: 0.95; }}
        .meta-item {{ display: flex; align-items: center; gap: 8px; }}
        .email-body {{ padding: 30px; line-height: 1.6; color: #000000; background-color: #ffffff; }}
        .email-body p {{ margin: 12px 0; color: #000000; }}
        .email-body ul {{ margin: 12px 0 12px 24px; color: #000000; }}
        </style>
        </head><body>
        <div class="email-viewer">
            <div class="email-header">
                <div class="email-subject">{email_subject}</div>
                <div class="email-meta">
                    <div class="meta-item"><strong>From:</strong> FSI AI Assistant</div>
                    <div class="meta-item"><strong>To:</strong> {recipient_email}</div>
                    <div class="meta-item"><strong>Date:</strong> {current_time}</div>
                </div>
            </div>
            <div class="email-body">
                {html_body}
            </div>
        </div>
        </body></html>"""
    else:
        html_content = email_content
    
    try:
        # Store email in EMAIL_PREVIEWS table for SnowMail viewer
        # Use parameterized query to avoid SQL injection and dollar-quote conflicts
        insert_query = """
        INSERT INTO ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS 
        (EMAIL_ID, RECIPIENT_EMAIL, SUBJECT, HTML_CONTENT, CREATED_AT)
        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP())
        """
        session.sql(insert_query, params=[email_id, recipient_email, email_subject, html_content]).collect()
        
        # Send email using SYSTEM$SEND_EMAIL
        # Escape single quotes in content for SQL string
        escaped_subject = email_subject.replace("'", "''")
        escaped_content = html_content.replace("'", "''")
        query = f"""
        CALL SYSTEM$SEND_EMAIL(
            'snowflake_intelligence_email_int',
            '{recipient_email}',
            '{escaped_subject}',
            '{escaped_content}',
            '{mime_type}'
        )
        """
        result = session.sql(query).collect()
        
        # Build SnowMail URL
        snowmail_url = f"https://app.snowflake.com/[org]/[account]/#/apps/application/SNOWMAIL"
        
        return f"""âœ… EMAIL SENT SUCCESSFULLY!

ðŸ“§ Email Details:
   Subject: {email_subject}
   To: {recipient_email}
   Email ID: {email_id}

ðŸ”— VIEW IN SNOWMAIL:
   {snowmail_url}

ðŸ“Œ Email has been stored in EMAIL_PREVIEWS table and sent via Snowflake email integration."""
        
    except Exception as e:
        return f'ERROR sending email: {str(e)}'
$$;

GRANT USAGE ON PROCEDURE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SEND_EMAIL_NOTIFICATION(VARCHAR, VARCHAR, VARCHAR, VARCHAR) TO ROLE ACCOUNTADMIN;
GRANT USAGE ON PROCEDURE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SEND_EMAIL_NOTIFICATION(VARCHAR, VARCHAR, VARCHAR, VARCHAR) TO ROLE PUBLIC;

-- =====================================================
-- SENTIMENT_WITH_TRANSCRIPTS_FOR_SEARCH View
-- =====================================================
-- Joins unique_transcripts with sentiment data
-- =====================================================

CREATE OR REPLACE VIEW ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SENTIMENT_WITH_TRANSCRIPTS_FOR_SEARCH AS 
SELECT 
    t.primary_ticker,
    t.event_timestamp,
    t.event_type,
    t.created_at,
    s.sentiment_score,
    s.unique_analyst_count,
    s.sentiment_reason,
    t.transcript AS FULL_TRANSCRIPT_TEXT,
    LENGTH(t.transcript) AS transcript_length
FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts t
LEFT JOIN ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS s
    ON t.primary_ticker = s.primary_ticker 
    AND t.event_timestamp = s.event_timestamp;

GRANT SELECT ON VIEW ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SENTIMENT_WITH_TRANSCRIPTS_FOR_SEARCH TO ROLE ACCOUNTADMIN;
GRANT SELECT ON VIEW ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SENTIMENT_WITH_TRANSCRIPTS_FOR_SEARCH TO ROLE PUBLIC;

-- =====================================================
-- Verification Queries
-- =====================================================

SELECT 'Data foundation loaded - RAW DATA ONLY' AS status,
       'âœ… EMAIL_PREVIEWS' AS table_1,
       'âœ… unique_transcripts' AS table_2,
       'âœ… STOCK_PRICES' AS table_3,
       'âœ… AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS' AS table_4,
       'âœ… SOCIAL_MEDIA_NRNT' AS table_5,
       'Run notebooks to generate AI-processed tables!' AS next_step;

SELECT 'EMAIL_PREVIEWS', COUNT(*) AS row_count FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS
UNION ALL
SELECT 'unique_transcripts', COUNT(*) FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.unique_transcripts
UNION ALL
SELECT 'STOCK_PRICES', COUNT(*) FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.STOCK_PRICES
UNION ALL
SELECT 'AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS', COUNT(*) FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.AI_TRANSCRIPTS_ANALYSTS_SENTIMENTS
UNION ALL
SELECT 'SOCIAL_MEDIA_NRNT', COUNT(*) FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.SOCIAL_MEDIA_NRNT;

-- =====================================================
-- WEB_SEARCH Function (External Access)
-- =====================================================
-- Uses DuckDuckGo - no API key required!
-- External access integration created in 01_configure_account.sql
-- =====================================================

CREATE OR REPLACE FUNCTION ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.WEB_SEARCH("QUERY" VARCHAR)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('requests','beautifulsoup4')
HANDLER = 'search_web'
EXTERNAL_ACCESS_INTEGRATIONS = (SNOWFLAKE_INTELLIGENCE_EXTERNALACCESS_INTEGRATION)
AS '
import requests
from bs4 import BeautifulSoup
import urllib.parse
import json

def search_web(query):
    encoded_query = urllib.parse.quote_plus(query)
    search_url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status() 
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        search_results_list = []
        
        results_container = soup.find(id="links")

        if results_container:
            for result in results_container.find_all("div", class_="result"):
                # Check if the result is an ad and skip it.
                if "result--ad" in result.get("class", []):
                    continue

                # Find title, link, and snippet.
                title_tag = result.find("a", class_="result__a")
                link_tag = result.find("a", class_="result__url")
                snippet_tag = result.find("a", class_="result__snippet")
                
                if title_tag and link_tag and snippet_tag:
                    title = title_tag.get_text(strip=True)
                    link = link_tag["href"]
                    snippet = snippet_tag.get_text(strip=True)
                    
                    # Append the result as a dictionary to our list.
                    search_results_list.append({
                        "title": title,
                        "link": link,
                        "snippet": snippet
                    })

                # Break the loop once we have the top 3 results.
                if len(search_results_list) >= 3:
                    break

        if search_results_list:
            # Return the list of dictionaries as a JSON string.
            return json.dumps(search_results_list, indent=2)
        else:
            # Return a JSON string indicating no results found.
            return json.dumps({"status": "No search results found."})

    except requests.exceptions.RequestException as e:
        return json.dumps({"error": f"An error occurred while making the request: {e}"})
    except Exception as e:
        return json.dumps({"error": f"An unexpected error occurred during parsing: {e}"})
';

GRANT USAGE ON FUNCTION ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.WEB_SEARCH(VARCHAR) TO ROLE ACCOUNTADMIN;
GRANT USAGE ON FUNCTION ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.WEB_SEARCH(VARCHAR) TO ROLE PUBLIC;

-- =====================================================
-- DEPLOYMENT COMPLETE - RAW DATA FOUNDATION
-- =====================================================

SELECT 'ðŸŽ‰ Data Foundation Complete!' AS status,
       'ðŸ“Š 5 raw data tables loaded' AS tables_loaded,
       'ðŸ““ Run Notebook 1 to generate: FINANCIAL_REPORTS, INFOGRAPHIC_METRICS_EXTRACTED, EMAIL_PREVIEWS_EXTRACTED' AS notebook_1,
       'ðŸ““ Run Notebook 2 to generate: TRANSCRIBED_EARNINGS_CALLS, SPEAKER_MAPPING, TRANSCRIBED_EARNINGS_CALLS_WITH_SENTIMENT, AI_TRANSCRIBE_NO_TIME, SENTIMENT_ANALYSIS, TRANSCRIPTS_BY_MINUTE' AS notebook_2,
       'ðŸ““ Run Notebook 4 to generate: INFOGRAPHICS_FOR_SEARCH, FULL_TRANSCRIPTS, call_embeds' AS notebook_4,
       'ðŸš€ Much faster and cleaner deployment!' AS benefit;

